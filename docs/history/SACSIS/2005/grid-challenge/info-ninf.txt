グリッドチャレンジにおける Globus Toolkit, Ninf-G の使い方

この文書は，主にグリッドチャレンジ環境において Globus Toolkit および
Ninf-G を利用する方法を具体例を示しながら説明したガイドラインである．
3 章以降で説明されている Ninf-G の使い方については，本文書とともに提供
されているサンプルプログラム(Ninf-G2-manual.tgz を展開すること)を参照
されたい．

目次
-------------------------------------------------------------------------
1. グリッドチャレンジにおけるグリッドソフトウェア環境
1.1 バッチシステム
1.2 Globus Toolkit
1.3 Ninf-G
1.3.1 Ninf-G で何ができるか
1.3.2 Ninf-G が提供していない機能

2. Globus の利用法およびテスト
2.0 Globus クイックスタートガイド
2.1 ユーザ証明書の取得
2.1.1 UNIX コマンドを用いる方法
2.1.2 Java Web Startを用いる方法
2.2 grid-mapfile へのエントリの追加
2.3 GT2 のテスト

3. Ninf-G の使い方
3.1 用語の解説と定義
3.2 仮定環境
3.3 サンプルプログラム
3.4 Ninf-G ユーザが用意するファイルと設定

4. 環境設定
4.1 Globus Toolkit 環境設定
4.2 Ninf-G 環境設定

5. Ninf-G を利用する前のプログラム

6. 単一マシンでの Ninf-G2 のテスト
6.1 サーバセットアップ
6.2 クライアントセットアップ
6.3 プログラムの Ninf-G 化

7. 複数マシンでの Ninf-G2 のテスト(2サイト)
8. 複数マシンでの Ninf-G2 のテスト(3サイト)
9. 1度のジョブ起動要求で複数のジョブを実行する
10. Ninf-G リモートオブジェクト機能を使用する
11. MPI を使用する

12. FAQ
Q1. サーバ名としてドメイン名は必須か．
Q2. 実行エラーの原因調査やログ出力に関して知りたい．
Q3. "GRAM Job failed" というエラーが発生する．
Q4. サーバホームディレクトリのファイル ~/gram_job_mgr_[数字].log は何か．
Q5. Ninf-G を利用したサンプルプログラムは無いか．
Q6. サーバでの計算が長時間になるがなにか注意することはないか．
Q7. non-thread flavor と pthread flavor のどちらを利用すれば良いか．
Q8. MDS とは何か．
Q9. デバッグ方法を知りたい．
Q10. ハートビート関連の Warning が出力された．
Q11. Ninf-G には共有メモリは用意されているか．
Q12. コンパイラやリンカの設定はできるか．
Q13. ジョブがすぐに実行されない．
Q14. workDirectory とは何か．
Q15. stdout, stderr がクライアントに転送されない．
Q16. ローカル LDIF ファイルの作成方法を知りたい．
-------------------------------------------------------------------------


-------------------------------------------------------------------------
1. グリッドチャレンジにおけるグリッドソフトウェア環境
グリッドチャレンジにおいては，すべてのクラスタに
  - バッチシステム(PBS または SGE)
  - Globus Toolkit Version 2.4 (GT2)
  - Ninf-G Version 2
がインストールされている．

1.1 バッチシステム
バッチシステムはユーザによって queue に投入されたジョブを順次実行する
システムであるが，特に以下のような機能を期待して導入されている：
  - ユーザがどの計算ホストを利用するかを意識せずに(指定することなく)，
    自動的に空いているノードを選択してユーザのジョブを実行する．
  - 多くのユーザがクラスタを共有する際に，同時に実行可能なジョブの数を
    制御し，ユーザに仮想的な占有環境を提供したり，あるいは過負荷状態に
    ならないようにする．
  - 全てのユーザが必ずバッチシステムを介して利用することにより，クラス
    タの利用状況や計算ホストで動いているプロセスの情報はバッチシステム
    により確認することができる．計算ホストに変なプロセスが残るような状
    況を防ぐことができる．
これらは大規模クラスタの運用/利用においては重要であり，実際，大規模ク
ラスタの多くはバッチシステムを導入し，利用に際しては必ずバッチシステム
を利用するよう利用方法を制限している．

グリッドチャレンジにおいてはバッチを介さずにsshなどにより対話的に(直接)
計算ホスト上でジョブを起動する方法も許されているため，バッチシステムが
動作を認識していないプロセスが計算ホストでも動作することになる．1台の
計算ホストで実行されるジョブの数を制限する(制御する)こともできない．ま
た，全クラスタで同時にジョブが起動されることを保証する必要があるため，
グリッドチャレンジ用にバッチシステムの設定を特殊なものに(1つの計算ホス
ト上で同時に多数のジョブが起動できるようにするなど)しており，本来バッ
チシステムに期待する上記の機能は提供されない．グリッドチャレンジにおい
ては，バッチシステムはただ単に計算ホスト上にジョブをディスパッチする事
を提供すると考えれば良い．

1.2 Globus Toolkit
Globus Toolkit はグリッドのソフトウェア，アプリケーションを開発，実行
するために必要な機能(の一部)を実装するための UNIX コマンドや C/Java の
API を提供するソフトウェアパッケージである．現在 Globus Toolkit は
Version 2, Version 3, および正式リリース直前の Version 4 が提供されて
いるが，グリッドチャレンジにおいては各クラスタに Globus Toolkit
Version 2 (GT2) がインストールされ，GT2 を介した遠隔利用が可能となって
いる．ここでは GT2 の詳細な説明は行なわず，GT2 がどのようにインストー
ルされているかを説明する．

各クラスタの入り口ホストでは Globus Gatekeeper が動作し，PBS または
SGE のバッチシステムを利用して計算ホストにジョブを起動するジョブマネー
ジャがデフォルトのジョブマネージャとして設定されている．つまり，ユーザ
はジョブマネージャを明示的に指定しない限り，バッチシステムを介して計算
ホストにジョブが起動されることになる．計算ホストでは Globus Gatekeeper
は動作しておらず，入り口ホストの Globus Gatekeeperおよびジョブマネージャ
を経由して計算ホストを利用することになる．ただし，計算ホストにも GT2
のライブラリはインストールされている．GT2 の利用およびテストの方法につ
いては後述する．

1.3 Ninf-G
Ninf-G はグリッドにおける遠隔手続き呼出し(Grid Remote Procedure Call,
GridRPC) によるプログラムの開発および実行を支援するソフトウェアである．
Ninf-G の最新版は Version 2 であり，グリッドチャレンジの全クラスタに
Ninf-G Version 2 (Ninf-G2) がインストールされている．GT2 が提供する
C/Java の API は非常に低レベルなものであり，それらを利用したアプリケー
ションの開発は非常に困難である．Ninf-G2 は GT2 の上位ミドルウェアとし
て，ユーザに対してはグリッドや GT2 が持つ複雑さを隠蔽し，グリッド上の
分散計算資源を利用するアプリケーションの開発・実行を支援する．Ninf-G
の詳細は本書第3章の「Ninf-G の使い方」および「Ninf-G Users' Manual」
(http://ninf.apgrid.org/documents/ng2-manual/user-manual.html)
を参照されたい．

1.3.1 Ninf-G で何ができるか
簡単に説明すると，Ninf-G を利用すると以下のことが可能となる．

  - RPC モデルによるプログラムの並列化
  - RPC モデルの利用によるグリッドプログラムの迅速な開発
  - 複数の計算サーバを利用した大規模計算
  - 計算サーバの動的な確保と利用，動的な解放
  - 計算サーバやネットワークの故障/障害の検知と回避のできる
      プログラムの開発

1.3.2 Ninf-G が提供していない機能
簡単に説明すると，Ninf-G は以下の機能を提供していない．
必要であれば，Ninf-G を利用するプログラムの側で実現するべき機能を以下
に挙げる．

  - スケジューリング機能
    (使用可能リソースの動的な検索や選択利用，
     計算サーバの負荷状況による動的な計算投入先の選択)
  - 障害検知後の自動的な計算の再投入
  - MPI プログラムを自動的に Ninf-G プログラムに変換する機能
  - 計算プログラムの自動並列化
  - 共有メモリモデルによる並列プログラミング
  - 計算サーバ自体の利用許可申請を含む，自動的な計算サーバの発掘と利用


-------------------------------------------------------------------------
2. Globus の利用法およびテスト
GT2 は Grid Security Infrastructure (GSI) というセキュリティに基づいて
リモート計算機へのアクセス等を実現している．GT2 あるいは Ninf-G2 を用
いたアプリケーションを実行するためには，ユーザ証明書の取得や GT2 が利
用可能ユーザを管理するサーバ側のファイル(grid-mapfile)へのエントリの登
録など，(セキュリティ的に) GT2 を利用する環境を整える必要がある．
ここでは，産総研が運用する認証局である AIST GTRC Certificate Authority
(AIST GTRC CA) からユーザ証明書を取得する方法，グリッドチャレンジ参加
サイトの計算機の grid-mapfile にエントリを登録してもらう方法および GT2 
を利用する環境が整ったかどうかをテストする方法について述べる．

2.0 Globus クイックスタートガイド
ここでは詳細な説明はせず，とりあえずグリッドチャレンジ環境で Globus
Toolkit を利用するための手順をまとめる．産総研のクラスタ
xcmp001.asc.hpcc.jp をクライアントマシン及びサーバマシンとして利用して
いる．詳細は 2.1 節以降を参照すること．

(1) Globus の準備
(1.1) ユーザ証明書を取得する (2.1 節参照)

(1.2) grid-mapfile へのエントリ登録依頼 (2.2 節参照)

(1.3) ユーザ証明書，秘密鍵が置かれていることを確認する．

  [yoshio@xcmp001 ~]$ ls -al .globus
  total 16
  drwx------    2 yoshio   yoshio       4096 Jan 14 11:55 .
  drwxr-xr-x    6 yoshio   yoshio       4096 Jan 14 11:55 ..
  -rw-rw-r--    1 yoshio   yoshio       1023 Jan 14 11:55 user_request.pem
  -rw-rw-r--    1 yoshio   yoshio       4908 Jan 14 12:01 usercert.pem
  -r--------    1 yoshio   yoshio        963 Jan 14 11:55 userkey.pem

(1.4) /etc/grid-security/grid-mapfile に自分のエントリがあることを確認
      する．
  [yoshio@xcmp001 ~]$ grep yoshio /etc/grid-security/grid-mapfile
  "/C=JP/O=AIST GTRC/CN=Yoshio Tanaka/emailAddress=yoshio.tanaka@aist.go.jp" yoshio

(1.5) globus-job-run のテスト
  [yoshio@xcmp001 ~]$ grid-proxy-init
  Your identity: /C=JP/O=AIST GTRC/CN=Yoshio Tanaka/emailAddress=yoshio.tanaka@aist.go.jp
  Enter GRID pass phrase for this identity:
  Creating proxy ............................................ Done
  Your proxy is valid until: Wed Jan 19 02:24:58 2005

  [yoshio@xcmp001 ~]$ globus-job-run xcmp001.asc.hpcc.jp /bin/hostname
  xcmp002.asc.hpcc.jp

  返されるホスト名はバッチシステムの割り当てに応じて異なる事に注意．

2.1 ユーザ証明書の取得
GSI は X.509 ユーザ証明書と公開鍵暗号を利用したセキュリティ基盤であり，
GT2 を利用するためには，ユーザはユーザ証明書を取得し，サーバ計算機にも
サーバ証明書を配備する必要がある．グリッドチャレンジにおいては，産業技
術総合研究所グリッド研究センターが運用する認証局の1つである AIST
GTRC CA が「信頼できる認証局」としてすべてのサイトの計算機に登録されて
いる．ここでは，AIST GTRC CA からユーザ証明書を取得する方法を説明する．
もしすでに AIST GTRC CA からユーザ証明書を取得している場合には，新たに
証明書を取得する必要はない．他の認証局(例えば Globus Simple CA を用い
て自分で立ち上げた認証局)が発行したユーザ証明書を利用している場合には，
別途 AIST GTRC CA からユーザ証明書を取得し，それを利用する必要がある．

公開鍵証明書を取得する手順はいくつかあるが，AIST GTRC CA からユーザ証
明書を取得する場合には，
[1] ユーザは秘密鍵と公開鍵を作成し，公開鍵を AIST GTRC CA に送る
[2] AIST GTRC CA は送付された公開鍵に署名をし(これがユーザ証明書)，ユー
    ザに送り返す
[3] 送付されたユーザ証明書を適切なファイルとして保存する
という手順を踏むことになる．

これらの手順等 AIST GTRC CA に関する詳細情報は
  https://www.apgrid.org/CA/AIST/index.html
に掲載されているが，AIST GTRC CA はユーザがユーザ証明書を取得する手段
として，UNIX のコマンドおよび Java Web Start を用いた GUI の2種類を提
供している．

2.1.1 UNIX コマンドを用いる方法
[1] 秘密鍵と公開鍵の作成
グリッドチャレンジに提供している産総研のクラスタ(xcmp001.asc.hpcc.jp)
にユーザ証明書を取得するためのコマンドが
  /usr/users/soum/bin/aist-cert-request
としてインストールされている．このコマンドを実行し，指示にしたがって自
分の氏名と電子メールアドレスを入力すること．以下に実行の様子を示す．
"^^^^^^^^^^" で示している部分が，自分で入力をする部分である．
また，PEM pass phrase を入力している部分 "**********" は実際にはエコー
バックされない．

======================================================================
[yoshio@xcmp001 ~]$ /usr/users/soum/bin/aist-cert-request 
Enter your name, e.g., John Smith: Yoshio Tanaka
                                   ^^^^^^^^^^^^^
Enter your e-mail address: yoshio.tanaka@aist.go.jp
                           ^^^^^^^^^^^^^^^^^^^^^^^^
Using configuration from /usr/users/yoshio/src/aist-csr/input/ssl.conf
Generating a 1024 bit RSA private key
..++++++
......++++++
writing new private key to '/usr/users/yoshio/.globus/userkey.pem'
Enter PEM pass phrase: **********
Verifying password - Enter PEM pass phrase: **********
-----
You are about to be asked to enter information that will be
incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or
a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [JP]:Level 0 Organization [AIST GTRC]:Name (e.g., John M. Smith) []:Email Address []:

****************************************************************************

Request (and private key) is in /usr/users/yoshio/.globus
private key is stored in userkey.pem
request is stored in user_request.pem

user_request.pem should be mailed to aist-ca@apgrid.org
****************************************************************************
======================================================================

名前の入力に際してはフルネームをローマ字で，電子メールアドレスもメール
を受け取ることのできる正しいメールアドレスを入力すること．AIST GTRC CA 
が発行した証明書はここで指定されたアドレスに電子メールで送付される．

上記コマンドを実行すると ~/.globus というディレクトリが作成され，そこ
に user_request.pem, usercert.pem, userkey.pem という3つのファイルが作
成される．引き続いてのステップで，証明書発行依頼である
user_request.pem を AIST GTRC CA に電子メールで送付する．

[2] 証明書発行要求の送付
証明書発行要求(Certificate Signing Request, CSR)である
user_request.pem ファイルを電子メールにて AIST GTRC CA に送付する．
xcmp001.asc.hpcc.jp に CSR を AIST GTRC CA に送付するためのコマンドが
  /usr/users/soum/bin/send-csr.sh
としてインストールされている．このコマンドを実行すること．以下に実行の
様子を示す．

======================================================================
[yoshio@xcmp001 ~]$ /usr/users/soum/bin/send-csr.sh
======================================================================

上記コマンドを実行すると，CSR が AIST GTRC CA に電子メールによって送付
される．AIST GTRC CA は CSR を受け取ると，申請情報が適切であるかどうか
を審査した上で証明書を発行し，発行した証明書を電子メールにて送付する．
証明書の送付先は CSR の送付元アドレスとなる．

[3] ユーザ証明書の保存
AIST GTRC CA からユーザ証明書が送付されたら，そのメールをファイルとし
て保存し(メールのヘッダ等がついたままで構わない)，そのファイルを
xcmp001.asc.hpcc.jp:~/.globus/usercert.pem にコピーする．このファイル
は CSR 作成時(aist-cert-requestコマンド実行時)にサイズがゼロとして生成
されているが，それを上書きして良い．

以上で，ユーザ証明書および秘密鍵が xcmp001.asc.hpcc.jp に配備されたこ
とになる．ファイルはそれぞれ

  ユーザ証明書： xcmp001.asc.hpcc.jp:.globus/usercert.pem
  秘密鍵：       xcmp001.asc.hpcc.jp:.globus/userkey.pem

である．秘密鍵のパーミッションは 400 となっていることに注意．秘密鍵は
他人に見られたり，あるいはそのパスフレーズを他人に知られてはいけない．

GT2 あるいは Ninf-G2 のクライアントを実行する計算機の ~/.globus ディレ
クトリにはこれらのファイルが置かれている必要がある．
xcmp001.asc.hpcc.jp 以外の計算機をクライアントとして利用する場合には，
これらのファイルを適切にコピーする必要がある．

2.1.2 Java Web Startを用いる方法
AIST GTRC CA は Java Web Start を用いて証明書取得申請を行なうツールを
提供している．Java Web Start を利用できる環境で以下のリンクをクリック
すると，必要なソフトウェアが適宜ダウンロードされ，証明書取得申請を行な
うためのダイアログが開かれる．

  https://www.apgrid.org/CA/AIST/csrgenerator.jnlp

以後指示にしたがって氏名，電子メールアドレスなどを入力し，CSR を AIST
GTRC CA に送付すれば良い．
AIST GTRC CA からユーザ証明書が送付されたら，そのメールをファイルとし
て保存し(メールのヘッダ等がついたままで構わない)，そのファイルを CSR
作成時に秘密鍵を格納したファイルが置かれたフォルダ(ディレクトリ)と同じ
フォルダ(ディレクトリ)に usercert.pem という名前でメールを保存する．こ
のファイルは CSR 作成時(aist-cert-requestコマンド実行時)にサイズがゼロ
として生成されているが，それを上書きして良い．

以上で，ユーザ証明書および秘密鍵が Java Web Start を起動した計算機に配
備されたことになる．ファイルはそれぞれ

  ユーザ証明書： usercert.pem
  秘密鍵：       userkey.pem

GT2 あるいは Ninf-G2 のクライアントを実行する計算機の ~/.globus ディレ
クトリにはこれらのファイルが置かれている必要がある．クライアントとして
利用する計算機にはこれらのファイルを適切にコピーする必要がある．

2.2 grid-mapfile へのエントリの追加
GT2 の認証においては，アクセスするサーバ計算機にユーザの情報が登録され
ている必要がある．具体的には，ユーザ証明書に書かれている Subject 名と，
そのユーザのジョブを実行すべき UNIX アカウントとの対応表(grid-mapfile)
にエントリを登録する必要がある．
ユーザ証明書を取得したら，グリッドチャレンジ管理者用メーリングリスト
  grid-challenge-admins@logos.t.u-tokyo.ac.jp
宛に，ユーザ証明書および各サイトでのアカウント名を送付して，
grid-mapfile へのエントリ登録を依頼すること．
すでにユーザ証明書を取得済みの場合も，同様にエントリ登録を依頼する必要
がある．

2.3 GT2 のテスト
GT2 を使ってグリッドチャレンジ参加サイトの計算機上でジョブを実行できる
かどうかを確認する．GT2 および Ninf-G2 を用いてアプリケーションを実行
する際には，事前にクライアント計算機上で grid-proxy-init コマンドを実
行して一時証明書を作成しておく必要がある．この一時証明書の有効期間は約
12時間であり，期限が切れた場合には再度 grid-proxy-init コマンドを実行
する必要がある．
以下の手順で動作確認ができる．

======================================================================
[yoshio@xcmp001 ~]$ grid-proxy-init
Your identity: /C=JP/O=AIST GTRC/CN=Yoshio Tanaka/emailAddress=yoshio.tanaka@aist.go.jp
Enter GRID pass phrase for this identity:**********
Creating proxy ................................ Done
Your proxy is valid until: Sat Jan 15 05:17:23 2005
======================================================================

GRID pass phrase では，証明書申請時に秘密鍵の暗号化に利用したパスフレー
ズを入力すること．入力している部分 "**********" は実際にはエコーバック
されない．

上記コマンドが成功した時点で一時証明書が作成され，サーバ計算機上でジョ
ブを実行する準備が整ったことになる．次に，GT2 が提供する UNIX コマンド
である globus-job-run を用いて GT2 を利用する環境が期待通り整備されて
いるかどうかを確認する．globus-job-run は rsh/ssh に似た引き数列を取る
コマンドである．
以下の手順で動作確認ができる．

======================================================================
[yoshio@xcmp001 ~]$ globus-job-run xcmp001.asc.hpcc.jp /bin/hostname
xcmp002.asc.hpcc.jp
======================================================================

上記は，クライアント，サーバのいずれも xcmp001.asc.hpcc.jp で起動した
場合のテストになる．他のサーバ(例えば Tauken)にジョブが投げられるかど
うかを確認するためには，

======================================================================
[yoshio@xcmp001 ~]$ globus-job-run istbs000.i.u-tokyo.ac.jp /bin/hostname
istbs001.i.u-tokyo.ac.jp
======================================================================

のように実行すれば良い．


-------------------------------------------------------------------------
3. Ninf-G の使い方
3章以降では，用意したサンプルプログラムをもとに，実際に Ninf-G を利用
する手順について解説する．

まず Ninf-G を利用しない逐次版の C プログラムを起点に，そのプログラム
を Ninf-G を利用するプログラムへと書き換え，徐々に利用方法を高度化す
る．

3章以降はサンプルプログラムを手元に置き，実際に手順を実行しながら確認
する形で読んで頂きたい．

3.1 用語の解説と定義
この章以降で利用する用語を定義し，Ninf-G を利用する際に使用する用語を
解説する．

  ユーザ:
    Ninf-G を利用したプログラムを作成する者をユーザとする．

  RPC 関数:
    Ninf-G では実際に数値計算を行う関数のことを指す．計算サーバ上で実
    行され，実行のためには計算サーバ上に計算リソース(CPU 計算時間，メ
    モリ)を必要とする．RPC 関数はユーザが作成するが，他のユーザが作成
    したRPC 関数を利用することもできる(RPC 関数を共有する)．
    (ユーザは計算リソースを必要とする関数を RPC 関数として設定する．)

  Ninf-G クライアント:
    RPC 関数を呼び出し，計算全体のコントロールを行うプログラムやプロ
    セスのことを指す．Ninf-G クライアントプログラムはユーザが作成する．

  Ninf-G Executable, Ninf-G サーバプログラム:
    RPC 関数として数値計算を行うためのプログラムのことを指す．Ninf-G
    クライアントから関数ハンドル作成時に起動される．起動すると RPC 関数
    実行(計算)の開始要求を待ち受ける．

  クライアントマシン :
    ユーザが Ninf-G クライアントプログラムを実行するマシン．

  サーバマシン :
    ユーザが Ninf-G サーバプログラムを実行するマシン．

  関数ハンドル:
    Ninf-G クライアントが RPC 関数を呼び出すために準備/作成する
    grpc_function_handle_t 型のデータのことであり，Ninf-G Executable
    と Ninf-G クライアントとの接続(通信路)を抽象化したもの．

    関数ハンドルを作成する際には，計算サーバ名を与える．1つの関数ハンド
    ルは計算サーバ上で起動された Ninf-G Executable プロセスと 1対1 対
    応する．

  IDL ファイル:
    IDL とは，Interface Description Language の略であり，IDL ファイルに
    は RPC 関数を呼び出すための入出力の型や並びを定義する．IDL ファイ
    ルはユーザが作成する．

    Ninf-G IDL では，実際の計算処理手続きや，IDL に記述された関数を実行
    するためにリンクが必要なオブジェクトファイル(.o で終わるファイル)
    等の指定をすることもできる．

    この，ユーザが作成した IDL ファイルを元に，Ninf-G サーバプログラムや
    ローカル LDIF ファイルが作成される．

  ローカル LDIF ファイル:
    ユーザが作成した RPC 関数を呼び出すための，引数の並びなどの情報が記憶
    されたファイル．

    IDL ファイルをサーバマシン上でコンパイルする際に作成され，クライアン
    トコンフィギュレーションファイルから読み込んで使用する．

なお，これ以降コマンドラインの説明において "%" および "$" にて始まる行が
ある．これは，それぞれシェル上のコマンドプロンプトを意味しており，
"%" で始まる場合は csh (Cシェル) や tcsh 上で実行していることを表す．
"$" で始まる場合は，sh (Brune シェル) や bash 上で実行していることを表す．

3.2 仮定環境
説明するにあたって，利用する環境を以下に示す．

  クライアントマシン : client.example.org
  サーバマシン       : server01.example.org から server02.example.org

上記のマシン名はそれぞれ仮定であり，実在しない．実際にサンプルを試す場合
には，ユーザが利用するマシン名にそれぞれ読み替えた上で編集/実行して頂き
たい．

3.3 サンプルプログラム
サンプルプログラムを下記に示す．

各サンプルが保存されているディレクトリ名を，":" の右側に記述している．

  章    内容                                        ディレクトリ名
  5. 章 Ninf-G を利用する前のプログラム            : serial
  6. 章 単一マシンでの Ninf-G2 のテスト            : 1site
  7. 章 複数マシンでの Ninf-G2 のテスト(2サイト)   : 2site
                                                 (上記 2つの内容は同じ)
  8. 章 複数マシンでの Ninf-G2 のテスト(3サイト)   : 3site
  9. 章 1度のジョブ起動要求で複数のジョブを実行する: array
  10.章 Ninf-G リモートオブジェクト機能を使用する  : object
  11.章 MPI を使用する                             : mpi

3.4 Ninf-G ユーザが用意するファイルと設定
Ninf-G を利用するために，ユーザが用意するファイルには以下のものがある．
サンプルプログラムには以下のものが含まれている．

  (1) サーバマシンに必要なファイル
    + IDL ファイル
    + ユーザが IDL ファイルにて指定した計算関数のオブジェクトファ
      イル，および，ライブラリファイル

  (2) クライアントマシンに必要なファイル
    + Ninf-G クライアントプログラム
    + コンフィギュレーションファイル
    + ローカル LDIF ファイル(IDL コンパイル時に生成される)

サンプルプログラムを実行する際には，以下の修正を行った上で実行する．

  - クライアントコンフィギュレーションファイルの修正を行う．
     ファイル中の "example.org" となっている箇所を，実際に使用するサー
     バのホスト名に修正する．

     + <SERVER> セクションの hostname を変更する．
     + <LOCAL_LDIF> セクションの filename に含まれるホスト名部分を変更
       する．


-------------------------------------------------------------------------
4. 環境設定
**********************************************************************
グリッドチャレンジにおいては，すべてのクラスタにおいてここで述べる環境
設定はログイン時に自動的に行なわれるに設定されており，ユーザが個別に設
定を行なう必要はない
**********************************************************************
Ninf-G を利用するためには，あらかじめ Globus Toolkit 及び，Ninf-G の
ユーザ環境設定を行う必要がある．尚，この設定はログイン毎に必要となる
が，シェルが起動毎に読み込むファイル(.cshrc, .login や，.profile,
.bashrc など)に手順を記述しておけば手動で設定する必要はなくなる．

4.1 Globus Toolkit 環境設定
Globus Toolkit のユーザ環境は，以下の手順で設定する．

     + 環境変数 GPT_LOCATION を GPT インストールディレクトリに設定する．
     + 環境変数 GLOBUS_LOCATION を Globus Toolkit インストール
       ディレクトリに設定する．
     + 環境設定ファイル globus-user-env.{sh,csh} を読み込む．

     (ユーザがシェルとして sh, bash を利用している場合の実行例)
       $ GPT_LOCATION=[GPT インストールディレクトリ]
       $ GLOBUS_LOCATION=[Globus Toolkit インストールディレクトリ]
       $ export GPT_LOCATION GLOBUS_LOCATION
       $ . $GLOBUS_LOCATION/etc/globus-user-env.sh

     (ユーザがシェルとして csh, tcsh を利用している場合の実行例)
       % setenv GPT_LOCATION [GPT インストールディレクトリ]
       % setenv GLOBUS_LOCATION [Globus Toolkit インストールディレクトリ]
       % source $GLOBUS_LOCATION/etc/globus-user-env.csh

4.2 Ninf-G 環境設定
Globus Toolkit のユーザ環境は，以下の手順で設定する．

     + 環境変数 NG_DIR を，Ninf-G インストールディレクトリに設定
     + 環境設定ファイル $NG_DIR/etc/ninfg-user-env.{sh,csh} 読み込み

     (ユーザがシェルとして sh, bash を利用している場合の実行例)
       $ NG_DIR=[Ninf-G インストールディレクトリ]
       $ export NG_DIR
       $ . $NG_DIR/etc/ninfg-user-env.sh

     (ユーザがシェルとして csh, tcsh を利用している場合の実行例)
       % setenv NG_DIR [Ninf-G インストールディレクトリ]
       % source $NG_DIR/etc/ninfg-user-env.csh


-------------------------------------------------------------------------
5. Ninf-G を利用する前のプログラム
Ninf-G を利用する前のサンプルプログラムを serial ディレクトリに用意した．

このサンプルプログラムは，モンテカルロ法により円周率πの値を計算し求める
簡易的なプログラムである．モンテカルロ法では，まず長さ 1の正方形中にラン
ダムな点を打つ．次にその点の原点からの距離が 1以内かどうか調べる．そして
，同じように何度も点を打ち距離を計測することによって円周率を求める．

円周率は，以下の式で求めている．

  円周率 ＝ 原点からの距離が 1以内だった点の数 ÷ 打った点の総数 × 4

この方法では，点を打った回数によって，求める円周率の精度が変化する．
求める円周率の精度を向上させたい場合，点を打つ回数を多くすればよい．

点を打つためには，多少の計算能力が必要であり，そのためより精度の良い結果
を得るためには，より多くの計算能力が必要である．そして，計算能力をより多
く利用する手段として，Ninf-G では RPC を用意している．

Ninf-G を利用する前のプログラム(pi_serial.c)では，単純に実行した場合，
計算能力，計算リソースとして 1つの CPU しか利用することはできない．
しかし，Ninf-G を利用すると，複数の計算サーバの CPU を同時/並列に
利用することでき，同じ計算時間内によりたくさんの点を打つことができるように
なる．その結果，精度の良い計算結果が得られるようになる．

このプログラムに利用されている pi_trial() 関数のように，計算結果を得る
ためには，入力として与えられた情報のみあればよく，後は計算するのみの
関数が一般的には RPC として適している．

以下の手順で，プログラムを実行する．

  (1) ディレクトリの移動
  % cd serial

  (2) コンパイル
  % make
  実行ファイル "pi_serial" が作成される．

  (3) 実行
  % ./pi_serial 100000
  結果，計算された円周率の値が表示される．100000 は打つ点の数であり，
  任意の数字を入力する．


-------------------------------------------------------------------------
6. 単一マシンでの Ninf-G2 のテスト
まずは，最も簡単な単一マシンのみの利用で Ninf-G の動作をテストする．

1つのクライアントプログラムで 1つのサーバプログラムを実行する．
クライアント・サーバは両方同じマシンで実行する．

   サンプルプログラム : 1site
   サーバマシン       : client.example.org (手順 6.1)
   クライアントマシン : client.example.org (手順 6.2)

   下記実行前にサンプルのディレクトリに移動する．
     % cd 1site

6.1 サーバセットアップ

 (1) IDL ファイルのコンパイル
       % ng_gen pi.idl

 (2) Ninf-G Executable 作成
       % make -f pi.mak

6.2 クライアントセットアップ

 (1) クライアントプログラムのコンパイル
       % ng_cc -o pi_client_single pi_client_single.c

     (ここまでの手順(サーバセットアップ (1)，(2)，および，クライアント
      セットアップ (1))のルールはサンプルプログラムの Makefile に
      記述されている．そのため，make コマンドの実行で代用できる．)

 (2) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
          (vi や emacs コマンド等のテキストエディタを利用する．)
       → "example.org" を "client.example.org" に修正する．
       → "pi.example.org.ngdef" を "pi.client.example.org.ngdef" に修正
          する．

 (3) クライアントプログラムの実行
       % grid-proxy-init
         'パスフレーズ入力'
         (なお，grid-proxy-init コマンドはクライアントの実行毎に毎回必要
          となるわけではない．作成した一時証明書の有効期限が切れるまでは，
          grid-proxy-init コマンドを再度実行する必要はない)

       % ./pi_client_single 10000 client.example.org

      pi_client_single は「打つ点の数」と「サーバホスト名」を引数で受け取る．

      ここで注意するのは，Ninf-G が利用する Globus Toolkit の特性として，
      ジョブの起動 1回につき数秒以上の時間が必要となるということである．
      Ninf-G としてはジョブの起動は，関数ハンドル作成に対応しており，
      関数ハンドルの作成に数秒以上の時間が必要である．

      そのため，実際の RPC 計算は 1秒以下であった場合でも，クライアント
      プログラムの実行には数秒以上の時間がかかってしまうことになる．

      また，この待ち時間はジョブのバッチシステム，キューイングシステム
      によっても変化する．バッチシステムが行うスケジューリング次第で，
      ジョブの起動がすぐには始まらず，他のジョブの終了まで待たされる可
      能性もある．

6.3 プログラムの Ninf-G 化
この章で実行した 1site/pi_cliet_single は，先ほど 5章で説明したプログラ
ムを Ninf-G 化したものである．

PI を計算する Ninf-G サーバプログラムは IDL ファイルである pi.idl の中
で定義されている．具体的には pi_trial() 関数を RPC 関数とし，Ninf-G を
経由して実行するように変更した．
それに伴い，pi_trial() 関数自体は，IDL ファイルから呼び出すように変更し，
その IDL で定義した RPC 関数 pi_trial() を Ninf-G クライアントプログラム
から呼び出している．

Ninf-G クライアントプログラムでは，定義した RPC 関数 pi_trial() を呼び出
すための手続きを追加している．追加した手続きは GridRPC API である以下の
関数を呼ぶものである．

  + Ninf-G を利用するための初期化/終了 API
    grpc_initialize(), grpc_finalize()

  + RPC を呼び出すための関数ハンドルの作成と破棄用 API
    grpc_function_handle_init(), grpc_function_handle_destruct()

  + 関数ハンドルに対し，RPC の実行を要求する API
    grpc_call()

  + RPC 実行の終了と結果を待つ API
    grpc_wait_all()

この GridRPC API を利用することで，Ninf-G を利用し RPC モデルによる
計算ができるようになった．


-------------------------------------------------------------------------
7. 複数マシンでの Ninf-G2 のテスト(2サイト)
次に，複数マシンを利用してテストを行う．

1つのクライアントプログラムで 1つのサーバプログラムを実行する．
クライアント・サーバは別々のマシンを用いる．

   サンプルプログラム : 2site
   サーバマシン       : server01.example.org (手順 7.1)
   クライアントマシン : client.example.org   (手順 7.2)

   下記実行前にサンプルのディレクトリに移動する．
     % cd 2site

7.1 サーバセットアップ
     サーバマシンにログインした後，2site ディレクトリに移動し，6.1 の手
     順と同様の操作を行う．
     (Makefile にもルールが記述されているため，make コマンドを実行
     するだけでもサーバプログラムが作成される．)

     この際，サーバマシンの名前を含むローカル LDIF ファイル
     "pi.server01.example.org.ngdef" も同時に作成される．このファイルは
     Ninf-G クライアントで利用するためのファイルである．
     
7.2 クライアントセットアップ

 (1) クライアントプログラムのコンパイル
     クライアントマシンにも別途ログインし，操作を行う．

       % ng_cc -o pi_client_single pi_client_single.c

 (2) ローカル LDIF ファイルのコピー
     server01.example.org 上の Ninf-G Executable をコンパイルした
     ディレクトリにある，"pi.server01.example.org.ngdef" を
     マシン client.example.org のクライアントを実行するディレクトリに
     コピーする．

       % scp server01.example.org:/path/to/pi.server01.example.org.ngdef .

     (この場合では，scp コマンドによりコピーしている．scp とは，
      SSH(Secure SHell:通信路を暗号化したリモート操作コマンド) に含まれ
      るプログラムである．この使用例では，リモートのファイルをカレントディ
      レクトリにコピーしている．)

 (3) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
       → "example.org" を "server01.example.org" に修正する．
       → "pi.example.org.ngdef" を
          "pi.server01.example.org.ngdef" に修正する．

 (4) クライアントプログラムの実行
       % grid-proxy-init
         'パスフレーズ入力'
       % ./pi_client_single 10000 server01.example.org

      pi_client_single は「打つ点の数」と「サーバホスト名」を引数で受け取る．

この手順により，client.example.org にて起動した Ninf-G クライアントプロ
グラムが，server01.example.org へ RPC の計算を要求することを確認した．

この，クライアントマシンとサーバマシンは地理的に全く離れた場所であって
もよい．このように Ninf-G を利用すると，ネットワークを介してリモートの
計算リソースを利用した計算を行うことが可能となる．組織をまたがった協調
した計算が可能となる．


-------------------------------------------------------------------------
8. 複数マシンでの Ninf-G2 のテスト(3サイト)
次に，複数の計算サーバを利用して並列に RPC を呼ぶテストを行う．

1つのクライアントプログラムで 2つのサーバプログラムを実行する．
クライアント・サーバはそれぞれ別のマシンで実行する．
ジョブを複数の計算サーバに振り分けることにより，並列に計算を行うことがで
きる．

   サンプルプログラム : 3site
   サーバマシン1      : server01.example.org (手順 8.1)
   サーバマシン2      : server02.example.org (手順 8.1)
   クライアントマシン : client.example.org   (手順 8.2)

   下記実行前にサンプルのディレクトリに移動する．
     % cd 3site

8.1 サーバセットアップ
     それぞれのサーバマシンにログインし，6.1 の手順と同様の操作を
     それぞれ行う．
     
8.2 クライアントセットアップ

 (1) クライアントプログラムファイルの修正
     6章，7章のテストで使用した pi_client_single.c を，複数のサーバを使用
     して計算を実行するように修正する．
     (修正後のソースファイルは pi_client_multi.c である．)

     ● 主な修正点
        - 利用する計算サーバが複数となるため，計算サーバに関連するデータ構
          造について，計算サーバの台数分の配列として用意する．
        - 関数ハンドルの作成，RPC の呼び出し，関数ハンドルの破棄を，利用
          するサーバの台数分だけそれぞれ繰り返す．

 (2) クライアントプログラムのコンパイル
       % ng_cc -o pi_client_multi pi_client_multi.c

 (3) ローカル LDIF ファイルのコピー
     server01.example.org，および，server02.example.org 上の
     Ninf-G Executable をコンパイルしたディレクトリにある，
     "pi.server01.example.org.ngdef"，および，
     "pi.server02.example.org.ngdef"を client.example.org にコピーする．

       % scp server01.example.org:/path/to/pi.server01.example.org.ngdef .
       % scp server02.example.org:/path/to/pi.server02.example.org.ngdef .

 (4) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
       → "example.org" を "server01.example.org" に修正する．
       → <SERVER> セクションの hostname に
          "hostname server02.example.org" という記述を追加する．
       → "pi.example.org.ngdef" を
          "pi.server01.example.org.ngdef" に修正する．次の行に
          "filename pi.server02.example.org.ngdef" と記述した行を追加す
          る．

 (5) クライアントプログラムの実行
       % grid-proxy-init
         'パスフレーズ入力'
       % ./pi_client_multi 10000 \
         server01.example.org server02.example.org

         (ここで，10000 の後の \ (行末のバックスラッシュ)は，コマンドラ
          インの入力を次の行に継続するという意味のシェルの機能である．)

      pi_client_multi は「打つ点の数」と「サーバホスト名」を引数で受け取る．
      「サーバホスト名」は複数指定可能で，引数で指定されたすべての
      ホストで計算を実行する．


この手順により，複数の計算サーバを用いて計算を並列に行うことができた．
このプログラムの場合，コマンドライン引数として与えられた「打つ点の数」
を，それぞれの計算サーバで分割して並列に計算するようにプログラムされてい
る．

そのため，このプログラムでは 1つのサーバを利用して計算する場合よりも，
2つのサーバを利用して計算した場合の方が計算の終了が速い結果となる．
「打つ点の数」が 10000 程度であれば，すぐに終了して並列の効果は分からな
いが，1つのサーバで計算した場合の計算時間が 1日などの長い時間である場合
複数のサーバを利用する効果は顕著に現れる．そして，利用する計算サーバの
数は多ければ多いほど計算時間は短くなる．


-------------------------------------------------------------------------
9. 1度のジョブ起動要求で複数のジョブを実行する
通常，1つのクラスタシステムは，複数の計算サーバ(計算ノード)を持っている．
そして，クラスタシステム(ジョブ投入ノード)に対し投入されたジョブを，順次
別々の計算ノードに割り振った上で実行する機能を有する．

Ninf-G から，それら計算ノードのいくつかを利用するためには，利用する数だけ
関数ハンドルを作成する必要がある．

しかし，関数ハンドルの作成は 1回実行するために最低でも数秒の時間が必要と
なってしまうため，複数の関数ハンドルを作成すると比例して時間がかかってし
まう．また，関数ハンドル作成要求をするたびに，入り口ホストにジョブマネー
ジャプロセスが起動されるため，数十あるいは数百を越える数の関数ハンドル
を単純な方法(関数ハンドルを1つずつ作成する方法)で作成すると，入り口ホ
ストが過負荷状態となってしまう．そこで，Ninf-G には一度の関数ハンドル
作成要求で，複数の関数ハンドルを一度に作成する機能が用意されている．こ
の機能を利用すると，関数ハンドルの作成時間を短縮するとともに，大量の
(数十〜数百の)関数ハンドルを作成することが可能となる．

この章ではこの機能を利用したテストを行う．

   サンプルプログラム : array
   サーバマシン       : server01.example.org (手順 9.1)
   クライアントマシン : client.example.org   (手順 9.2)

   下記実行前にサンプルのディレクトリに移動する
     % cd array

9.1 サーバセットアップ
     サーバマシン(クラスタ管理ノード)にログインし，6.1 の手順と同様の操作
     を行う．
     
9.2 クライアントセットアップ

 (1) クライアントプログラムファイルの修正
     8章の例題で使用した pi_client_multi.c を，複数の関数ハンドルを一度
     に作成するための API grpc_function_handle_array_init_np() を使用して
     関数ハンドルを作成するよう修正する．
     (修正後のソースファイルは pi_client_array.c)

     ● 主な修正点
        - 複数回の grpc_function_handle_init() 呼び出しを
          1回の grpc_function_handle_array_init_np() に修正した．

 (2) クライアントプログラムのコンパイル
       % ng_cc -o pi_client_array pi_client_array.c

 (3) ローカル LDIF ファイルのコピー
     server01.example.org 上の Ninf-G Executable をコンパイルした
     ディレクトリにある，"pi.server01.example.org.ngdef"，
     をマシン client.example.org にコピーする．

       % scp server01.example.org:/path/to/pi.server01.example.org.ngdef .

 (4) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
       → "example.org" を "server01.example.org" に修正する．
       → "pi.example.org.ngdef" を
          "pi.server01.example.org.ngdef" に修正する．

 (5) クライアントプログラム実行
       % grid-proxy-init
         'パスフレーズ入力'
       % ./pi_client_array 10000 server01.example.org 4

      pi_client_array は「打つ点の数」・「サーバホスト名」・「ハンドル数」
      を引数で受け取る．

     コマンドライン最後の 4 は，作成する関数ハンドルの数である．例として
     4 を使用したが， 4 である必要はない．
     利用しているクラスタシステムが，ほかのユーザと共同利用している場合，
     作成するハンドルの数には注意し，許可されている範囲内で使用するよう
     気をつけること．

このプログラムでは関数ハンドル作成時のオーバーヘッドを削減するとともに，
入り口ホストで起動されるジョブマネージャの数を少なく保つ「関数ハンドル
一括生成機能」を利用している．これは大規模クラスタシステム(数十〜数千
プロセッサ規模)を利用するためには必須な技術である．

-------------------------------------------------------------------------
10. Ninf-G リモートオブジェクト機能を使用する
Ninf-G Executable は状態を持たない(state less)．つまり，同じ関数ハンド
ルを用いて繰り返し RPC 関数を呼び出したとしても，前回の呼び出し時の状
態は Ninf-G Executable には保持されていない．そのため，同じデータに対
して何度か計算を行なうような場合でも毎回データを送信する必要がある．

Ninf-G2 は状態を保持する事を可能にした Ninf-G Executable をリモートオ
ブジェクトとして提供している．リモートオブジェクトには複数の関数(メソッ
ド)を定義することができ，Ninf-G クライアントがそれらのメソッドを呼び出
すための機能を提供している．

リモートオブジェクト機能を利用する場合は，ハンドルは関数ハンドルではなく
オブジェクトハンドルを作成する．オブジェクトハンドルは
grpc_object_handle_t_np 型のデータであり，リモートオブジェクトと
Ninf-G クライアントとの接続(通信路)を抽象化したものである．オブジェク
トハンドルを作成した後，破棄するまでは対応するリモートオブジェクトが状
態を保持することができる．そして，そのオブジェクトハンドルに対し，状態
を変更する様々なメソッドを呼ぶこともできる．

例えば，RPC の入力データが非常に大きく，かつ各 RPC 呼び出し間で入力データ
が全く同じ場合には，リモートオブジェクト機能が有効に利用できる．各ハンド
ル作成後に 1度だけその大きな入力データを渡す初期化メソッドを呼び出し
Ninf-G Executable に保存するようにすれば，それ以降の各 RPC 呼び出しでは
その大きな入力データの転送が不要となり性能が改善される．

別の例として，1つの Ninf-G クラスに以下のメソッドを実装する例を挙げる．

    - 初期化処理メソッド :
        引数を与える．その与えられた引数は，データ保持領域に保存する．
    - 計算1メソッド      :
        保持されたデータを使用して計算1 を実行する．得られた途中結果は，
        データ保持領域に保存する．結果は返さない．
    - 計算2メソッド      :
        保存された途中結果より，計算2 を実行する．計算2 によって得られた
        最終結果をクライアントに返す．

   サンプルプログラム : object
   サーバマシン       : server01.example.org (手順 10.1)
   クライアントマシン : client.example.org   (手順 10.2)

   下記実行前にサンプルのディレクトリに移動する．
     % cd object

10.1 サーバセットアップ
     
 (1) IDL ファイルの修正
     6 〜 9章で使用した IDL ファイル pi.idl を，オブジェクト化する．
     (修正後のソースファイルは pi_object.idl)
       pi_object.idl を編集する．

     ● 主な修正点
        - Define を DefClass に変更した．
        - 関数の処理内容を DefMethod pi_trial に移動した．

 (2) IDL ファイルのコンパイル
       % ng_gen pi_object.idl

 (3) Ninf-G Executable 作成
       % make -f pi_object.mak

10.2 クライアントセットアップ

 (1) クライアントプログラムファイルの修正
     7章の例題で使用した pi_client_multi.c を，Ninf-G リモートオブジェク
     ト機能を使用して計算を実行するように修正する．
     (修正後のソースファイルは pi_client_object.c)

     ● 主な修正点
        - 呼び出す関数名を修正した．
        - grpc_function_handle から始まる API とデータ構造をすべて
          grpc_object_handle から始まる API，データ構造を利用するように
          修正した．

 (2) クライアントプログラムのコンパイル
       % ng_cc -o pi_client_object pi_client_object.c

 (3) ローカル LDIF ファイルのコピー
     server01.example.org 上の Ninf-G Executable をコンパイルした
     ディレクトリにある，"pi.server01.example.org.ngdef"，
     をマシン client.example.org にコピーする．

   % scp server01.example.org:/path/to/pi_object.server01.example.org.ngdef .

 (4) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
       → "example.org" を "server01.example.org" に修正した．
       → "pi_object.example.org.ngdef" を
          "pi_object.server01.example.org.ngdef" に修正した．

 (5) クライアントプログラムの実行
       % grid-proxy-init
         'パスフレーズ入力'
       % ./pi_client_object 10000 server01.example.org

      pi_client_object は「打つ点の数」と「サーバホスト名」を引数で受け取る．

-------------------------------------------------------------------------
11. MPI を使用する
Ninf-G は MPI で書かれた並列プログラムを RPC 関数として設定することが
できる．この機能を利用することにより，今まで述べてきたマスター/ワーカ
型に基づくタスク並列的なプログラミングの他に，遠隔手続き呼び出しを行なっ
たサーバマシン上で MPI による細粒度並列処理を行なうプログラミングも可
能となる．

   サンプルプログラム : mpi
   サーバマシン       : server01.example.org (手順 11.1)
   クライアントマシン : client.example.org   (手順 11.2)

   下記実行前にサンプルのディレクトリに移動する
     % cd mpi

11.1 サーバセットアップ
     
 (1) IDL ファイルの修正
     6 〜 9章で使用した IDL ファイル pi.idl を，MPI を利用したものに
     書き換える．(修正後のソースファイルは pi_mpi.idl)
       pi_mpi.idl ファイルを編集する．

     ● 主な修正点
        - Compiler, Linker に mpicc を指定した．
        - Backend で "MPI" を指定した．
        - 関数のインターフェイスを修正した(引数を減らした)．
        - 計算関数内で MPI の関数を記述した．
          MPI の各 rank で計算を行うために，与えられた引数や計算結果を
          MPI 通信により交換するコードを追加した．

 (2) IDL ファイルのコンパイル
       % ng_gen pi_mpi.idl

 (3) Ninf-G Executable の作成
       % make -f pi_mpi.mak

11.2 クライアントセットアップ

 (1) クライアントプログラムファイルの修正
     6章，および，7章の例題で使用した pi_client_single.c を，
     MPI を使用して計算を実行するように修正する．
     (修正後のソースファイルは pi_client_mpi.c)

     ● 主な修正点
        - 呼び出す関数名を修正した．
        - grpc_call() で渡す関数の引数を修正した．

 (2) クライアントプログラムのコンパイル
       % ng_cc -o pi_client_mpi pi_client_mpi.c

 (3) ローカル LDIF ファイルのコピー
     server01.example.org 上の Ninf-G Executable をコンパイルした
     ディレクトリにある，"pi_mpi.server01.example.org.ngdef"，
     をマシン client.example.org にコピーする．

      % scp server01.example.org:/path/to/pi_mpi.server01.example.org.ngdef .

 (4) コンフィギュレーションファイルの修正
       client.conf ファイルを編集する．
       → "example.org" を "server01.example.org" に修正した．
       → mpi_runNoOfCPUs の値を，使用する CPU 数に調整する．
       → "pi_mpi.example.org.ngdef" を
          "pi_mpi.server01.example.org.ngdef" に修正した．

 (5) クライアントプログラムの実行
       % grid-proxy-init
         'パスフレーズ入力'
       % ./pi_client_mpi 10000 server01.example.org

      pi_client_mpi は「打つ点の数」と「サーバホスト名」を引数で受け取る．
      ここで使用する CPU の数は，(4) で示した通りコンフィギュレーション
      ファイルの SERVERセクションの mpi_runNoOfCPUs で指定している．
      他にも Ninf-G では MPI の CPU 数を指定する方法がいつくかあるが，
      別の方法については Ninf-G ユーザーズマニュアルを参照されたい．

MPI は既存の並列システムにおける並列プログラミングモデルとして有名であ
り，MPICH-G2 などのグリッド対応の MPI 実装を用いることにより，既存の
MPI プログラムをそのままグリッド上で実行できるという利点がある．その一
方，グリッドにおいては，MPI が必要とする co allocation (プログラム実行
開始時に，すべてのMPI プロセスが起動されなければならない)を保証するこ
とは非常に難しい．また，process spawning などの機能を使えばある程度対
応可能であるが，基本的には MPI は利用するプロセッサ，プロセス数などが
静的に決定されるものであり，グリッドが持つ動的な性質とは相性が悪い．さ
らに，大規模環境で大規模アプリケーションを長時間実行する事はグリッドの
最大の魅力の1つであるが，そのような状況では計算ホストのハードウェア障
害など，障害発生時にどのように対処できるかといった点が重要になる．しか
し，MPI はどれか1つのプロセスに障害が発生した場合，その時点で全体のプ
ログラムの実行が中止されてしまうなど，耐障害性の機能が弱い．

GridRPC は上記に示した問題点に対応可能なプログラミングモデルである．co
allocation は必ずしも必要ではなく，関数ハンドルを動的に生成/破棄するこ
とによる動的な資源の追加/解放が容易である．また，どこかの計算ホストで
障害が発生した場合にも他の計算ホストで行なわれている計算には影響せず，
また，その計算ホストでの計算を破棄する，あるいは再度依頼するなどの形で
障害発生時の対応を容易に実現できる．

MPI は，並列に計算を行う場合に人気のあるプログラミングモデルである．し
かし，現状では必ずしも MPI の計算モデルに適していないプログラムまでも
がMPIで記述されていることも多い．
実装するアプリケーションの性質に応じて，最適なプログラミングモデルが選
択されるべきであり，「独立した1つ以上の計算をグリッド上の分散資源で実
行」するタイプであれば，(少なくとも MPI ではなく) GridRPC を使って実装
されるべきである．また，ここで述べた「詳細で密に通信する必要のある計算
の部分は MPI が担当し，通信が疎でよい部分は Ninf-G を利用する」という
GridRPC と MPI を組み合わせる方法を用いることにより，双方のプログラミ
ングモデルの利点を活かした大規模アプリケーションを実装することが可能で
ある．

-------------------------------------------------------------------------
12. FAQ
過去に質問された項目や，注意した方が良い項目などを以下に挙げる．

Q1. サーバ名としてドメイン名は必須か．

  Q. grpc_function_handle_init() API により関数ハンドルを作成する時には
     サーバ名が必要だが，このサーバ名はドメイン名を省略してもよいか?
     それともドメイン名を付ける必要があるか?

  A. ドメイン名は必須である．
     関数ハンドル作成時やクライアントコンフィギュレーションファイル作成
     時に，サーバ名は FQDN (Fully Qualified Domain Name) にて指定する．
     また，"localhost" は指定できない．正確に FQDN を指定しない場合，
     Ninf-G API がエラーで終了する．

     例えば，サーバとして server.example.org を利用する場合，"server"
     とは指定できない．必ず "server.example.org" と指定する．

Q2. 実行エラーの原因調査やログ出力に関して知りたい．

  Q. Ninf-G を利用するクライアントプログラムを作成し実行したが，うまく実
     行されていないようだ．Ninf-G API の実行に失敗しているようである．何
     か原因の追求方法は無いか?

  A. Ninf-G には，カスタマイズ可能なログ出力の機能がある．クライアントコ
     ンフィギュレーションファイルや，サーバのコンフィギュレーションファ
     イルにログ関連の設定をすることで，Ninf-G API 実行時のエラー情報やデ
     バッグ情報等を出力させることができる．出力先はファイルへ設定すること
     もできる．

     このログ機能を利用すると，Ninf-G API 実行の状態を確認することが可能
     であり，API 実行の失敗原因をトレースすることができる．

     ログ機能設定の詳細は，Ninf-G ユーザーズマニュアルを参照されたい．
     http://ninf.apgrid.org/documents/ng2-manual/user-manual.html
     (クライアントのログ出力設定 : 4.3.9節)
     (サーバのログ出力設定 : 3.3.2節)

     ログ出力メッセージは，それぞれ以下の順で出力される．
     "日付 時刻:クライアント/サーバ:ホスト名:ログレベル:
             各データ構造のID:Ninf-G内部関数名:ログメッセージ"

     また，Ninf-G のすべての API は実行の成功, 失敗を表す  grpc_error_t
     型の値を返す．これらの値は，ユーザプログラムで必ずチェックするよう
     プログラムを記述した方がよい．

     Ninf-G Executable にて実行される計算関数が Segmentation fault を起こ
     しているような場合には，クライアントコンフィギュレーションファイル
     の <SERVER> セクション coreDumpSize 属性が有効な場合もある．

Q3. "GRAM Job failed" というエラーが発生する．

  Q. grpc_call() や grpc_call_async() がエラーで終了する．この原因は何
     か? エラー発生時のエラーのログを出力すると，
      "ngcllJobCallback: GRAM Job failed because ..." といった
     ログメッセージが出力されている．

  A. "GRAM job failed" といったエラーが出力される場合には， Ninf-G が利用
     している Globus Toolkit のジョブ実行モジュールである GRAM がエラー
     となっている．

     GRAM がエラーとなる原因には様々なものがあり，一概に判別することはで
     きない．エラーメッセージ毎に対処方法は異なる．

     あるサーバの GRAM が正常に利用できるかを判断するには，コマンドライン
     から以下のコマンドを実行する．

     % globus-job-run server.example.org /bin/hostname

     上記コマンドは，server.example.org の GRAM に対し，/bin/hostname コ
     マンドの実行を要求する．成功した場合，ホスト名が表示される．このコ
     マンドを実行することにより，問題の解決となる場合がある．

     GRAM の失敗について，Globus の Web ページにエラーメッセージと対処の
     方法について言及がある．
     http://www.globus.org/about/faq/errors.html

     また，Ninf-G クライアントのログレベルを Information や Debug へと設
     定することで，クライアントが GRAM へ渡した GRAM RSL
     (Resource Specification Language : 実行環境指定言語)を確認すること
     もできる．

Q4. サーバホームディレクトリのファイル ~/gram_job_mgr_[数字].log は何か．

  Q. Ninf-G を利用した際，サーバのホームディレクトリに
     gram_job_mgr_[数字].log というファイルが作成されていた．
     このファイルは何か?

  A. このファイルは，Ninf-G が利用している Globus Toolkit のジョブ実行モ
     ジュールである GRAM の出力するログファイルである．

     GRAM は，ジョブを実行すると jobmanager プロセスを同時に起動する．
     jobmanager プロセスはジョブを監視し，終了の検知や，強制終了などを行
     う．

     jobmanager はジョブが正常終了した場合は，ログファイルを消去するが，
     何らかのエラーが発生したり，ジョブの実行がキャンセルされた場合には，
     ログファイルを消去しない．
     そのため，ホームディレクトリに GRAM のログファイルが残ることとなる．

     Ninf-G クライアントの場合，grpc_function_handle_init() API により関
     数ハンドルを作成したあと，grpc_function_handle_destruct()
     にて関数ハンドルを破棄する前に，クライアントを ^C キーにより，強制
     終了した場合などに ハンドルに該当するジョブがキャンセルされる．

     そのため結果的に，正常終了しなかった場合にはサーバのホームディレク
     トリに gram_job_mgr-[数字].log というファイルが残ってしまう．

     ジョブ終了の原因を追求する必要がなければ，このファイルは削除しても
     よい．
  
Q5. Ninf-G を利用したサンプルプログラムは無いか．

   Q. Ninf-G を利用したプログラムを作成しようと思うが，書き方が分からな
      い．サンプルプログラムは無いか?

   A. Ninf-G パッケージには，Ninf-G を利用したサンプルプログラムが用意
      されている．

      Ninf-G は，Ninf-G ダウンロードの Web ページから得ることができる．
      http://ninf.apgrid.org/packages/welcome.shtml
      
      このページより，Ninf-G version 2 パッケージをダウンロードする．

      このパッケージの中には，4つのプログラムが用意されている．
      test/samples/pi     : モンテカルロ法により円周率を求める．
      test/samples/add    : 配列の加算を行う．
      test/samples/pi_mpi : MPI を利用して計算を行う．
      test/diag           : Ninf-G が正常に利用できるかどうかを
                            確認する網羅的なテストを行う．

Q6. サーバでの計算が長時間になるがなにか注意することはないか．

   Q. 関数ハンドルを作成した後，数日以上そのハンドルを利用する予定である．
      この際気をつけることはないか?

   A. 一時証明書の有効期限に注意すること．grid-proxy-init コマンドは，
      無指定の場合の有効期限を 12時間として一時証明書を生成する．

      12時間以上関数ハンドルを利用したい場合は，2つの方法がある．

        1. grid-proxy-init コマンドの -valid オプションを利用する．
        2. Ninf-G の Refresh Credentials 機能を利用し，定期的に
           一時証明書を再作成しながら計算を継続する．

Q7. non-thread flavor と pthread flavor のどちらを利用すれば良いか．

  Q. Globus Toolkit には non-thread flavor と pthread flavor が用意され
     ており，Ninf-G はどちらでもコンパイル可能である．どちらを利用すれば
     よいか?

  A. pthread flavor を利用することをお勧めする．Ninf-G クライアントには
     pthread flavor にてコンパイルしなければ利用できない機能があるため，
     クライアントは pthread flavor を利用した方がよい．

     しかし，その機能が必要なければどちらの flavor を利用しても問題ない．
     また，Ninf-G Executable も同様，どちらを利用しても問題ない．

     もし，ユーザが記述するプログラムが Pthreads を利用したプログラム
     であれば，Ninf-G も pthread flavor を利用する必要がある．

     尚，Globus Toolkit は non-thread flavor, pthread flavor のどちらで
     も仕様上はほぼ同じ機能を提供するが，内部実装が全く異なるため，利用
     する flavor によって性能の差が発生する．

Q8. MDS とは何か．

  Q. Ninf-G は MDS を利用するようである． MDS とは何か? 利用する必要は
     ないのか．

  A. MDS とは，Globus Toolkit が提供する情報サービスである．Ninf-G は，
     MDS を利用することができる．MDS を利用して，計算サーバにインストー
     ルされた各 RPC の情報を得ることができる．

     しかし，この情報はローカル LDIF ファイルを利用しても得ることができ
     るため，必ずしも MDS を利用する必要はない．

     尚，MDS を利用する場合には以下の点に注意が必要である．

       - MDS は，Globus Toolkit ディレクトリに，Ninf-G RPC 関数情報を
         インストールして利用する．Globus Toolkit ディレクトリ以下の
         var/gridrpc に，(MDS の内部実装である LDAP が参照するための)
         LDIF ファイルをインストールすることで情報が提供される．
         しかし，MDS はキャッシュ機能を持っており，更新には 10分程度の
         時間がかかる場合がある．そのため，LDIF ファイルインストール直後
         は情報検索に失敗する時がある．
         
         尚，どのような RPC がインストールされているかは，Ninf-G の
         ng_dump_functions コマンドを利用して参照することができる．

       - MDS を利用するために LDIF ファイルをインストールするディレクト
         リは，共有ディレクトリである．個人個人で別のディレクトリが用意
         されているわけではない．そのため，同じ計算サーバ上に，同じ名前
         の RPC 関数を複数の人が同時に作成し，インストールすることはでき
         ない．

         ディレクトリが共有されているため，他のユーザの迷惑とならないよ
         う注意して利用する必要がある．

       - VO_NAME をあらかじめ知っておく必要がある．
         MDS にて検索する場合には，情報を要求したいサーバに設定されている
         VO_NAME を知っておく必要がある．VO_NAME を知らなければ検索はでき
         ない．もし，MDS サーバにログインが可能であれば，
         Globus Toolkit ディレクトリ以下の etc/grid-info-slapd.conf を
         参照すると VO_NAME が分かる可能性が高い．

Q9. デバッグ方法を知りたい．

  Q. Ninf-G Executable はリモートで起動されるため，デバッグが難しい．
     なにか方法はないか?

  A. Ninf-G には，Ninf-G Executable のデバッグ方法が用意されている．
     クライアントコンフィギュレーションファイルにて，<SERVER> セクション
     には，debug_busyLoop, debug, coreDumpSize が設定できる．詳細はユーザ
     ーズマニュアルを参照されたい．

     また，Ninf-G のログ出力機能もデバッグ時には有効である．クライアント
     と Ninf-G Executable 双方ともログの出力を行うことができ，Ninf-G API
     の実行状況を逐一確認することができる．

Q10. ハートビート関連の Warning が出力された．

  Q. Ninf-G クライアントのログ出力として，以下のようなメッセージが出力さ
     れた．問題はないか?

     "... heartbeat timeout warning (60 seconds) occurred ..."

  A. 必ずしも問題が発生しているとは言えない．
     ハートビートとは，Ninf-G Executable プロセスが正常に動作しているか
     ，フリーズしていないか，ネットワークに問題がないかを検知するための
     Ninf-G の機能である．

     Ninf-G Executable は，クライアントに対し定期的にハートビートを送信
     している．そのためもし，ネットワークがフリーズしていたり，Ninf-G
     Executable がフリーズしている場合は，ハートビートが Ninf-G
     Executable からクライアントへ届かなくなる．

     ハートビートが Ninf-G クライアントへ一定時間届かなかった場合，クラ
     イアントはその Ninf-G Executable (関数ハンドル)を，「異常状態であり
     利用できなくなったもの」と判断し，エラーとする．その関数ハンドルは
     もう利用できない．実行中の RPC はエラーで返る．

     Ninf-G クライアントはこの機能によって，フリーズすること無く障害の
     発生を検知することができる．そのため，ユーザは故障や障害に強い
     プログラムを作成することが可能である．

     Ninf-G Excutable がハートビートを送信する間隔を 60秒とした場合，
     ハートビートの Warning が出力されるのは，Ninf-G クライアントに
     60秒間ハートビートが届いていない場合である．そのため，Ninf-G
     Executable の処理が少々遅滞し，ハートビートの定期的な送出が少し
     遅れてしまった場合にも Warning は出力される．この状態はまだ異常で
     あるとは断言できない．

     デフォルトの設定では，ハートビートの送信間隔は 60秒であり，ハートビー
     トを受信しなかった場合に異常だと判断するタイミングは，
     60秒 x 5回 = 300秒の間ハートビートを受信しなかった場合となっている．
     (詳細はユーザーズマニュアルを参照されたい．)

     なお，ハートビート Warning が出力された後，以下のメッセージが出力
     された場合は，ハートビートの送信が正常に戻ったことを意味する．

     "... heartbeat revived again ..."

Q11. Ninf-G には共有メモリは用意されているか．

  Q. Ninf-G を利用しようと考えているが，Ninf-G には何らかの共有メモリ
     機構は用意されているか? Ninf-G Excutable 間で変数の値を共有する
     ことはできないか?

  A. Ninf-G には，共有メモリ機能は無い．Ninf-G Executable 間で変数の値を
     共有する機構は用意されていない．

Q12. コンパイラやリンカの設定はできるか．

  Q. コンパイラやリンカの設定はできるか?

  A. 可能である．IDL ファイルの構文には，Compiler, Linker などが用意され
     ている．

Q13. ジョブがすぐに実行されない．

  Q. 関数ハンドルを作成しても，ジョブがすぐに実行されない．そのため，
     grpc_call() API や grpc_call_async() API が止まってしまう．
     このようなことは起こるのか?

  A. 起こり得る．例えば，ジョブ投入先のクラスタの利用者が多く，他のジョ
     ブが優先されて実行される場合は，他のジョブが終了するまで待たされ
     ることがある．必ずすぐに実行されるわけではない．
     
     もし，ジョブの起動時間にタイムリミットを設けたい場合は，
     クライアントコンフィギュレーションファイルの <SERVER> セクションに，
     job_startTimeout 属性を設定すればよい．

Q14. workDirectory とは何か．

  Q. クライアントコンフィギュレーションファイルに設定可能な属性
     workDirectory とは何か?

  A. workDirectory とは，Ninf-G Executable のプロセスが動作するための
     ディレクトリを指定する機能である．デフォルトでは，Ninf-G Executable
     は，Ninf-G Executable プログラムが置かれているディレクトリにて動作
     する．このディレクトリを変更したい場合に利用する．

     RPC 関数/計算関数にて，相対パス指定によりファイルをオープンした場合
     は，この workDirectory を起点としてファイルがオープンされる．

     また，計算関数の不具合により Segmentation fault が起こった場合には，
     異常終了時のメモリイメージである core ファイルが出力される場合があ
     るが，この core ファイルが出力されるディレクトリも workDirectory に
     指定されたディレクトリとなる．

     指定された workDirectory が存在しない場合には，エラーとなるため注意
     が必要である．

     クラスタのジョブ投入ノードと実際にジョブが実行される計算ノードが別
     である場合にも注意する必要がある．Globus Toolkit の制約により，
     例え計算ノードには workDirectory が存在していても，ジョブ投入ノード
     には指定された workDirectory が存在しなければエラーとなってしまう．

Q15. stdout, stderr がクライアントに転送されない．

  Q. IDL ファイルや計算関数中に，printf() や fprintf() によって文字列を
     出力したが，その表示がクライアントに転送されない．
     クライアントコンフィギュレーションファイルには <SERVER> セクション
     に redirect_outerr true と設定している．なぜ転送されないのか?

  A. Ninf-G は，計算関数内の stdout, stderr の転送のため，Globus Toolkit
     GASS モジュールの提供する，stdout, stderr 転送機能を利用している．

     GASS stdout, stderr 転送機能では，転送タイミングが Globus Toolkit
     GRAM が利用する jobmanager 毎に異なる．そのため，転送タイミングは
     同じでは無い．

     例えば，jobmanager-fork を利用すると，1行出力される毎に数秒後には
     クライアントの stdout, stderr に転送され表示される．

     しかし，別の jobmanager の場合，ジョブの終了時に出力内容が一気に
     転送されることもある．この場合，Ninf-G の関数ハンドルを
     grpc_function_handle_destruct() によって破棄するまでは転送されない
     ことになる．

     また，なんらかの理由でジョブがキャンセルされると転送されないことも
     ある． Ninf-G の場合，当該ハンドルとの間にコネクションの異常切断な
     ど何らかのエラーが発生すると安全のためジョブのキャンセルを発行する
     ．

     そして，Ninf-G クライアントが grpc_function_handle_destruct() を実
     行する前に exit() などにより終了してしまった場合も転送されない．

Q16. ローカル LDIF ファイルの作成方法を知りたい．

  Q. 私の利用するクラスタシステムでは，関数ハンドル作成時の指定先ホスト
     である GRAM ジョブ投入ノード(例: server01.example.org) にはログイン
     が許可されておらず，server01.example.org での Ninf-G Executable の
     コンパイルができない．
     そのため server01.example.org 用のローカル LDIF ファイルが作成され
     ない．どのようにすればよいか?

  A. ローカル LDIF ファイルはテキストファイルであり，内容はユーザが書き
     換え可能である．

     例えば，以下のようにすれば server01.example.org 用のローカル LDIF
     ファイルが得られる．

       - まず，対象となる RPC 用 IDL ファイルを server01.example.org 以
         外のホスト(例: client.example.org)でコンパイルする．すると
         client.example.org 用のローカル LDIF ファイルが作成される．

       - 次に，そこで得られたローカル LDIF ファイルをテキストエディタに
         て書き換える．

         書き換える部分は，ローカル LDIF ファイル中のホスト名が記述され
         ている部分のすべてである．
         (client.example.org を server01.example.org に書き換える．)

       - ローカル LDIF ファイルのファイル名にも，ホスト名が含まれている
         が，こちらはクライアントの実行には影響がない．ただし，混乱の
         原因となり得るため，ファイル名も server01.example.org へと変更
         した方がよい．

     Ninf-G クライアントコンフィギューレーションファイルでは，上記の手順
     で作成したローカル LDIF ファイルを指定するとよい．

     尚，ローカル LDIF ファイルのユーザによる書き換えについては，自己責
     任で行うこと．

以上．
